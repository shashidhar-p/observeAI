# ==============================================================================
# Multi-Agent RCA System Configuration
# ==============================================================================

# ==============================================================================
# LLM Provider Configuration
# ==============================================================================
# Choose your LLM provider: 'anthropic' (cloud) or 'ollama' (local)
LLM_PROVIDER=ollama

# --- Anthropic Configuration (if LLM_PROVIDER=anthropic) ---
# Get your API key from https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-api03-your-key-here
# Model to use (claude-sonnet-4-20250514, claude-3-haiku-20240307, etc.)
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# --- Ollama Configuration (if LLM_PROVIDER=ollama) ---
# Ollama server URL (run 'ollama serve' to start)
OLLAMA_BASE_URL=http://localhost:11434
# Model to use (run 'ollama pull llama3.1:8b' to download)
# Recommended models with tool calling: llama3.1:8b, mistral:7b, mixtral:8x7b
OLLAMA_MODEL=llama3.1:8b
# Timeout for Ollama requests (local models can be slower)
OLLAMA_TIMEOUT_SECONDS=300

# Database (Required)
# PostgreSQL connection URL with asyncpg driver
DATABASE_URL=postgresql+asyncpg://rca:rca@localhost:5432/rca_db

# Observability Backends (Required)
# Loki for logs (LogQL queries)
LOKI_URL=http://localhost:3100
# Cortex for metrics (PromQL queries)
CORTEX_URL=http://localhost:9009

# Server Settings
HOST=0.0.0.0
PORT=8000
DEBUG=true

# RCA Configuration
# Time window (seconds) for grouping related alerts into incidents
CORRELATION_WINDOW_SECONDS=300
# Maximum iterations for the RCA agent loop (prevents infinite loops)
RCA_MAX_ITERATIONS=10
# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# RCA Expert Context (Optional)
# Custom domain expertise to inject into the RCA agent's system prompt.
# Leave empty to use the default network engineer context.
# For multi-line values, use \n for newlines or set via code.
# Example: RCA_EXPERT_CONTEXT="You are a Kubernetes expert. Focus on pod scheduling issues..."
RCA_EXPERT_CONTEXT=

# Timeouts (seconds)
# Timeout for Loki queries
LOKI_TIMEOUT_SECONDS=30
# Timeout for Cortex queries
CORTEX_TIMEOUT_SECONDS=30
# Timeout for Claude API calls
CLAUDE_TIMEOUT_SECONDS=120
